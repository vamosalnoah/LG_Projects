{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "forecast_pipeline.py\n",
    "\n",
    "Skeleton pipeline to forecast weekly sellâ€‘out units for TV SKUs across multiple retail chains\n",
    "using LightGBM + skforecast.  Every step is annotated so you understand *what* happens and *why*.\n",
    "\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ðŸ”§  WHAT YOU NEED TO FILL IN BEFORE RUNNING\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "1.  DATA SOURCES\n",
    "    â€¢ Path(s) to the raw CSV / Parquet files   OR   a SQLAlchemy connection URL.\n",
    "    â€¢ Column mapping â€“ rename here if your names differ:\n",
    "        â”€ date:              \"fecha\"\n",
    "        â”€ product id:        \"sku\"\n",
    "        â”€ retail chain id:   \"cadena\"\n",
    "        â”€ units sold:        \"sellout_u\"\n",
    "        â”€ revenue:           \"sellout_m\"\n",
    "        â”€ inventory (Sun):   \"inventario\"\n",
    "        â”€ sellâ€‘in units:     \"sellin_u\"\n",
    "        â”€ promo flags / weight(s): one column per promo or a single numeric weight.\n",
    "        â”€ technology:        \"tecnologia\"   (LCD, OLEDâ€¦)\n",
    "        â”€ size inches:       \"tamano\"\n",
    "\n",
    "2.  FORECAST SETTINGS\n",
    "    â€¢ FORECAST_H = 16            # horizon in *weeks*\n",
    "    â€¢ LEVEL_KEYS  = [\"cadena\", \"tecnologia\", \"tamano\"]  # hierarchy you want one model per combo\n",
    "\n",
    "3.  VALIDATION WINDOWS\n",
    "    â€¢ SPLIT_DATE = \"2024â€‘10â€‘06\"   # last date used for training (YYYYâ€‘MMâ€‘DD)\n",
    "\n",
    "4.  OPTIONAL\n",
    "    â€¢ GRANULARITY = \"W\"  # \"W\" for weekly (recommended), \"D\" if you stay at daily level.\n",
    "\n",
    "Replace the values inside CONFIG below or load them from a YAML/ENV.\n",
    "\"\"\"\n",
    "\n",
    "# ===========================================================================\n",
    "# 1 â”€ Imports & Config\n",
    "# ===========================================================================\n",
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# ML libs\n",
    "from lightgbm import LGBMRegressor\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "###############################################################################\n",
    "# Configuration dataclass keeps all tunables in one place\n",
    "###############################################################################\n",
    "@dataclass\n",
    "class CONFIG:\n",
    "    # â”€â”€ paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    DATA_DIR: Path = Path(\"./data\")\n",
    "    SALES_FILE: str = \"sellout.csv\"       # adjust\n",
    "    INVENTORY_FILE: str | None = None     # join later if separate\n",
    "    PROMO_FILE: str | None = None\n",
    "\n",
    "    # â”€â”€ columns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    DATE_COL: str = \"fecha\"\n",
    "    UNIT_COL: str = \"sellout_u\"\n",
    "    REV_COL: str = \"sellout_m\"\n",
    "    INV_COL: str = \"inventario\"\n",
    "    SELLIN_COL: str = \"sellin_u\"\n",
    "\n",
    "    ID_COLS:   list[str] = field(default_factory=lambda: [\"cadena\", \"sku\"])\n",
    "    CAT_COLS:  list[str] = field(default_factory=lambda: [\"tecnologia\", \"tamano\"])\n",
    "    PROMO_COLS:list[str] = field(default_factory=lambda: [\"promo_hot_sale\", \"promo_bf\"])\n",
    "\n",
    "    # â”€â”€ modelling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    GRANULARITY: str = \"W\"      # resample freq\n",
    "    FORECAST_H: int = 16        # horizon (weeks)\n",
    "    LAGS: int = 14              # how many past observations as features\n",
    "    SPLIT_DATE: str = \"2024-10-06\"\n",
    "\n",
    "CFG = CONFIG()\n",
    "\n",
    "# ===========================================================================\n",
    "# 2 â”€ Data Loading\n",
    "# ===========================================================================\n",
    "\n",
    "def load_sales() -> pd.DataFrame:\n",
    "    \"\"\"Load raw daily sellâ€‘out.  Replace with SQL if needed.\"\"\"\n",
    "    sales_path = CFG.DATA_DIR / CFG.SALES_FILE\n",
    "    df = pd.read_csv(sales_path, parse_dates=[CFG.DATE_COL])\n",
    "    return df\n",
    "\n",
    "# ===========================================================================\n",
    "# 3 â”€ Preâ€‘processing & Feature Engineering\n",
    "# ===========================================================================\n",
    "\n",
    "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean types, derive price & weekly aggregation if requested.\"\"\"\n",
    "    # â–‘â–‘ Derive average selling price â–‘â–‘\n",
    "    df[\"precio\"] = (df[CFG.REV_COL] / df[CFG.UNIT_COL]).replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # â–‘â–‘ Resample / aggregate â–‘â–‘\n",
    "    if CFG.GRANULARITY == \"W\":\n",
    "        # Sunday as weekâ€‘ending (ISOâ€‘like). Using pandas' Wâ€‘SUN label.\n",
    "        agg_dict = {\n",
    "            CFG.UNIT_COL: \"sum\",\n",
    "            CFG.REV_COL: \"sum\",\n",
    "            \"precio\": \"mean\",\n",
    "            CFG.INV_COL: \"last\",     # keep Sunday inventory\n",
    "            CFG.SELLIN_COL: \"sum\",\n",
    "            **{col: \"max\" for col in CFG.PROMO_COLS},\n",
    "        }\n",
    "        df = (\n",
    "            df\n",
    "            .set_index(CFG.DATE_COL)\n",
    "            .groupby(CFG.ID_COLS + CFG.CAT_COLS)\n",
    "            .resample(\"W-SUN\")\n",
    "            .agg(agg_dict)\n",
    "            .reset_index()\n",
    "        )\n",
    "    \n",
    "    # â–‘â–‘ Fill missing values â–‘â–‘\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    # â–‘â–‘ Cyclical date features â–‘â–‘\n",
    "    df[\"weekofyear\"] = df[CFG.DATE_COL].dt.isocalendar().week.astype(int)\n",
    "    df[\"sin_woy\"] = np.sin(2 * np.pi * df[\"weekofyear\"] / 52)\n",
    "    df[\"cos_woy\"] = np.cos(2 * np.pi * df[\"weekofyear\"] / 52)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ===========================================================================\n",
    "# 4 â”€ Train / Validation split & Model setup\n",
    "# ===========================================================================\n",
    "\n",
    "def make_train_test(df: pd.DataFrame):\n",
    "    train = df[df[CFG.DATE_COL] <= CFG.SPLIT_DATE].copy()\n",
    "    test  = df[df[CFG.DATE_COL] >  CFG.SPLIT_DATE].copy()\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def build_forecaster(lags: int = CFG.LAGS) -> ForecasterAutoreg:\n",
    "    \"\"\"Create skforecast wrapper around LightGBM.\"\"\"\n",
    "    reg = LGBMRegressor(objective=\"poisson\", random_state=42)\n",
    "    forecaster = ForecasterAutoreg(regressor=reg, lags=lags)\n",
    "    return forecaster\n",
    "\n",
    "# ===========================================================================\n",
    "# 5 â”€ Hyperâ€‘parameter search per hierarchy combo\n",
    "# ===========================================================================\n",
    "\n",
    "def train_per_combo(df: pd.DataFrame):\n",
    "    all_results = []\n",
    "    for keys, gdf in df.groupby(CFG.ID_COLS + CFG.CAT_COLS):\n",
    "        print(f\"\\nðŸ›   Training model for combo: {keys}\")\n",
    "        train, test = make_train_test(gdf)\n",
    "        y_train = train[CFG.UNIT_COL]\n",
    "        y_test  = test[CFG.UNIT_COL]\n",
    "\n",
    "        exog_cols = [c for c in gdf.columns if c not in CFG.ID_COLS + CFG.CAT_COLS + [CFG.DATE_COL, CFG.UNIT_COL]]\n",
    "        exog_train = train[exog_cols]\n",
    "        exog_test  = test[exog_cols]\n",
    "\n",
    "        forecaster = build_forecaster()\n",
    "\n",
    "        param_grid = {\n",
    "            \"regressor__max_depth\": [3, 5, 7],\n",
    "            \"regressor__learning_rate\": [0.05, 0.1, 0.2],\n",
    "            \"regressor__n_estimators\": [200, 500],\n",
    "        }\n",
    "        forecaster, grid_results = grid_search_forecaster(\n",
    "            forecaster=forecaster,\n",
    "            y=y_train,\n",
    "            exog=exog_train,\n",
    "            param_grid=param_grid,\n",
    "            steps=CFG.FORECAST_H,\n",
    "            metric=\"mae\",\n",
    "            refit=True,\n",
    "            verbose=False,\n",
    "        )\n",
    "        # â”€ Evaluation â”€\n",
    "        preds = forecaster.predict(steps=len(y_test), exog=exog_test)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        print(f\"MAE: {mae:.3f}\")\n",
    "\n",
    "        # Store\n",
    "        result = {\n",
    "            \"combo\": keys,\n",
    "            \"mae\": mae,\n",
    "            \"best_params\": forecaster.regressor.get_params()\n",
    "        }\n",
    "        all_results.append(result)\n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# ===========================================================================\n",
    "# 6 â”€ Main execution\n",
    "# ===========================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    raw  = load_sales()\n",
    "    data = preprocess(raw)\n",
    "    perf = train_per_combo(data)\n",
    "\n",
    "    # Save results\n",
    "    perf.to_csv(\"model_performance.csv\", index=False)\n",
    "    print(\"\\nâœ… Training finished.  Results saved to model_performance.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
